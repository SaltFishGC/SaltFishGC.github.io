---
title: 常见业务问题以及八股文
date: 2025-12-26
---

### Java中的Hashmap

使用hash算法得到hashcode，经过二次扰动优化使得所得索引分布更加均匀，根据最终所得索引插入对应数组索引位置（这个数组元素可以称之为bucket桶）的链表/红黑树（jdk8以后）

数组默认使用链表存储数据，链表超过某一长度（默认为8）使用红黑树存储key所对应value值，当退化到一定长度（默认为6）时会转化为链表

同时，hashmap在检测到冲突导致一个链表长度超过阈值时，还会先检测长度是否小于设定值（默认为64），若是小于这个值，则会先进行扩容（之所以链表会变长，一定程度上就是因为数组长度不够，所得索引不够分散导致聚一块而插一个链表里面去了）而不是树化，而且只有发生哈希冲突、链表长度超过阈值（默认为 8）且数组容量 ≥ 64 的那个桶（bucket）才会被树化（转换为红黑树）**，**其他位置保持不变。

为什么使用红黑树？

让树的深度变小，平均查找长度变小



### ConcurrentHashmap

和普通的hashmap最主要的功能区别就是他是一个线程安全的hashmap，简单来讲，就是会为每一个桶（jdk8+）准备一个锁（且是非显式锁，而是借助`synchronized`对桶的头结点加锁的隐式锁），多线程下，对一个桶内的值操作时，需要先去获取这个桶所对应的锁。

Jdk7中：`ConcurrentHashMap` 使用 **`Segment` 分段锁**（默认 16 个 Segment），每个 Segment 管理若干桶，**不是每个桶一个锁**。

Jdk8+中：

- 当多个线程同时操作同一个桶

  （比如都往同一个链表/红黑树插入）：

  - 会 **对这个桶的头节点对象使用 `synchronized` 加锁**；
  - 例如：`synchronized (f)`，其中 `f` 是该桶的第一个节点。

- 不同桶之间 **完全无锁竞争**，可并行操作。

**为什么不用“每个桶一个显式锁”？**

- 节省内存：如果数组长度 16，就有 16 把锁；但若长度 100 万，不可能创建 100 万个 `ReentrantLock` 对象；
- `synchronized` 在 JVM 优化后（偏向锁、轻量级锁）性能极高，且自动释放，更安全。



**扩容数组长度：**

- **插入元素后，总元素数量超过阈值**
   - 阈值 = `容量 × 负载因子`（默认负载因子 0.75）

   - 例如：初始容量 16 → 阈值 ≈ 12，第 13 个元素插入时可能触发扩容


- 或者**链表长度 ≥ 8 且当前数组长度 < 64**
     - 此时**优先扩容**，而不是转红黑树（因为小容量下 hash 冲突高，扩容更有效）


**转红黑树：**

- **某个桶（bucket）中的链表长度 ≥ 8**同时**当前 table 数组长度 ≥ 64**



**是所有 bucket 一起转红黑树，还是单个转？**

**答案：单个 bucket 独立转换！**

- **只对当前发生插入/更新的桶（bin）做判断**
- 其他桶即使链表很长，也不会自动转树（除非它们也被访问到）
- 转换过程对该 bin 加锁（`synchronized`），保证线程安全

当然也可以设置相应的阈值，当减少bucket的元素时，红黑树变回链表

| 行为         | 触发条件                                              | 作用范围        | 是否并发安全 | 备注           |
| :----------- | :---------------------------------------------------- | :-------------- | :----------- | :------------- |
| **扩容**     | 总元素数量>阈值 **或** 链表长度≥8 且 table数组长度<64 | **整个 table**  | ✅ 是         | 多线程协助迁移 |
| **转红黑树** | 链表长度≥8 **且** table数组长度≥64                    | **单个 bucket** | ✅ 是         | 仅当前操作的桶 |
| **退化链表** | TreeNode数量 ≤ 6                                      | **单个 bucket** | ✅ 是         | 删除时触发     |

所有情况下，新加元素时**先检查总元素个数是否达到阈值**，若已经达到阈值，则先扩容，再看是否有**某一链表长度达到阈值**的情况发生。

**整体长度不长**的时候**某一链表长度达到阈值**，认为先变长数组能有效解决冲突问题，把数组变长，使其分布均匀。

**整体长度较长**的时候**某一链表长度达到阈值**，认为变长数组效率不够好，可以考虑将该链表转化为红黑树，减少冲突时查找长度。



### 缓存与数据库的数据一致性

| 模式                        | 流程                                                         | 一致性   | 性能   | 复杂度 | 适用场景                  |
| :-------------------------- | :----------------------------------------------------------- | :------- | :----- | :----- | :------------------------ |
| **Cache-Aside（旁路缓存）** | 读：先查缓存 → 未命中查 DB → 回填缓存 写：先更新 DB → **删除缓存** | 最终一致 | ⚡ 高   | ✅ 低   | **最常用！** 读多写少场景 |
| **Read/Write Through**      | 缓存层代理读写，自动同步 DB                                  | 强一致   | 中     | ⚠️ 高   | 需要封装缓存中间件        |
| **Write Behind（异步写）**  | 先写缓存 → 异步批量刷 DB                                     | 弱一致   | ⚡ 极高 | ❌ 极高 | 日志、监控等容忍丢失场景  |

> ✅ **绝大多数业务（如电商、社交）采用 Cache-Aside + 删除缓存策略**

 **🔹 Write Through（写穿透）的定义：**

- 应用程序**只写缓存**
- 缓存层**同步写数据库**
- 对应用透明，像“穿透”到 DB

**Cache-Aside（旁路缓存）**和另外两个的区别是后端服务会根据缓存的返回结果直接操作数据库，而另外两个后端只会读写缓存，对数据库的操作或是交由缓存处理，或是定时任务处理，不会由执行读写操作的当前后端线程进行。

| 模式                        | 应用层（后端服务）是否直接操作 DB？ | 缓存层是否代理 DB 操作？   |
| :-------------------------- | :---------------------------------- | :------------------------- |
| **Cache-Aside（旁路缓存）** | ✅ **是** （应用自己读写 DB）        | ❌ 否 （缓存只是被动存储）  |
| **Read/Write Through**      | ❌ **否** （应用只读写缓存）         | ✅ 是 （缓存自动同步 DB）   |
| **Write Behind**            | ❌ **否** （应用只写缓存）           | ✅ 是 （缓存异步批量写 DB） |
